\section{Related Works}

Artificial intelligence is a large research area that includes machine learning, and expert system topics.
Expert systems have two major components: an inference engine and a knowledge base.
Machine learning models are best defined by their knowledge base, network architecture, activation function and number of parameters.

\subsection{Causal Learning}
In ML a `model' is an algorithm or set of algorithms trained to recognize a very limited sub-class of pattern.
It refers to a replica of the environmental and situational conditions that lead to an observable outcome or data at a manageable scale.
CI describes its usefulness using the `ladder of causation', which has three levels: association, intervention and counterfactuals \cite{Pearl:2018}.
An example of questions that can be answered by association:
\begin{itemize}
    \item What does a sore throat tell me about the severity of the flu?
    \item If I experience dizziness does that necessitate inner ear trouble?
\end{itemize}

Example questions that can be answered by intervention:
\begin{itemize}
    \item If I drink hot water with lemon and ginger will my cold symptoms disappear?
    \item Will taking the same Covid-19 vaccine 3 times ensure I'll never have "severe" Covid-19 symptoms?
\end{itemize}

Example questions that can be answered by deploying counterfactuals:
\begin{itemize}
    \item If I had done heavy exercise 6 times a week for the past decade, would I be an Olympic level athlete?
    \item If I had not been exposed to high levels of mosquito repellent and steel soot as a young child, would I still have asthma?
\end{itemize}

At the second level of the ladder of causation, intervention, the base data alone can not answer the question.
For instance, data can answer that many people reported feeling relief from cold symptoms, and tell us the percentage, possibly of people who gel better who have profiles similar to oneself.
Intervention questions are usually answered using experimentation, while with CI these questions will be answerable using its techniques.

As we found in the summary of deep learning in omics reviews people need to trust the data, algorithms and techniques used for translational medicine, phenotype prediction, precision medicine, advanced therapeutics and more.
A good way to understand is by asking ``why'', and as Judea Pearl \cite{Pearl:1995} \cite{Pearl:2009} \cite{Pearl:2019} has explained in his multiple works is by using causal inference.