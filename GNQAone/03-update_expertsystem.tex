\section{Updating the Expert System}
In academia and industry the term expert system has lost its luster.
Expert systems ended up only seeming like experts to those with the vocabulary for the task for which it was designed.
AI researchers, before the age of ubiquitous deep learning, almost all have experience designing and building expert systems of one type or another, giving us insight on the strengths and weaknesses of these types of systems.
The main weaknesses of expert systems, before the age of GPT-3 type LLMs and powerful generative AI, are the inclusion of new information (data ingestion) and the ability to make smart inferences on all knowledge available to it.
LLMs have an uncanny knack for information ingestion and inference; however, due to the way neural networks learn information perfect inference is not a possibility.
Because perfect inference is not possible even when deduced by models with billions of parameters, the expert system must guide the output of the model by querying a knowledge base of data on which the system is to be an expert.
LLMs allow the interface to the expert system to be accessible by anyone who can speak a language that it can understand.
LLMs understand natural language and can perform high-level inference in response to natural language making them an extremely important component of an evolved expert system.
An expert system requires an inference engine and a knowledge base.
Modern LLms provide the inference engine, while the knowledge based can be curated, and finally the process must be moderated such that LLM hallucination can not interfere with the results; because what use is an expert system that will not tell you the truth?

\subsection{Not Just Machine Learning (ML)}

A system should be built that supports researchers of varying levels of ability.
This system should be able to communicate well with people with differing levels of knowledge who seek variable levels of atomicity.

\subsection{Improving LLMs with Causality} % Conclusion

