\subsection{Weaknesses in LLMs}
A major problem with \llms\ is the unproven high level of trust placed in them by excited users.
A small anecdote referneces a genomics Ph.D. student who told me in early 2023 that ChatGPT is close to `perfect' as it responds in a manner she deems favourable to more than 90\% of her prompts.
This statement, although from a Ph.D. student was without qualification or data.
It is likely the use cases to which her prompts belong were in the list of those ChatGPT handles well, and she was possibly not an expert on the subjects with which she prompted the system.
Data is not referenced when answers are generated.
LLMs and generative AI have the same issues in that pure fact patterns are not mapped, similarities are mapped and based on the data available.
While the model is being trained it learns, and in the case of \gpts\ class models learns well, associations and not facts.

Bias perpetuation
Reconstruct protected data
Information hallucination
Little to on explainability
General logic errors
Susceptibility to prompt injection

\subsection{Mitigating the weaknesses of an open LLM}
\subsubsection{How much data?}
ChatGPT was trained on multitudinous data scoured from all over the internet. 
With this almost indeterminate information grab comes petabytes of information, which required extreme effort to curate.
\subsubsection{Which data?}
Is all data good data?
Due to the nature of the world wide digital web (www) \textbf{bias} is prevalent, and training a model on highly biased information leads to biased results [mention the algorithmic justice league].
\subsubsection{Re-introducing Oracles}
In simple language a software Oracle is like an advanced lookup/hash table or data tuple where each entry has a single matter-of-fact answer.
An Oracle is generally a master of a special area of knowledge.
In the real world, an Oracle is an expert.
Medical practitioners are Oracles; however, they are Oracles with specializations concerning how different systems of the human body works and how it responds to multitudinous treatments.
There are many different types of medical practitioners, one group of which are nurses.
Nurses have different levels of expertise on the human body, how people react to treatment, real-life human-drug interactions, and sub-specialties, e.g. Renal nurse, Mid-wife (birthing) nurse, pediatric nurse, neonatal ICU nurse, emergency room nurse, oncology nurse, surgery nurse, post-surgery nurse, and so on.
Each nurse has different expertise that spans not only written medical knowledge, but also experience from interacting face-to-face with living patients.
People may have the same major malady yet need to be given differing treatments based on their personality traits, not any other underlying medical conditions.
Being able to encode this knowledge into an Oracle is nothing new, while it takes care and attention [cite many expert systems].
Part of the inference of an expert system is being able to, for example, take malady's and the knowledge of nurses to come up with the best treatment for an individual.
Also, it would be wonderful to be able to know how often a prescribed treatment works, and how well.

\begin{comment}
Each nurse has undergone specialized training to become and expert and then learned thru practice.
In nursing practice there are many variables involved when discerning and providing treatment.
A model is fed with knowledge, like a nurse being trained, and the models' practice is interacting with experts and being told whether or not the answers it is giving are correct given the query.
\end{comment}