@ARTICLE{Azaria:2022,
  TITLE       = {{ChatGPT Usage and Limitations}},
  AUTHOR      = {Azaria, Amos},
  URL         = {https://hal.science/hal-03913837},
  NOTE        = {working paper or preprint},
  YEAR        = {2022},
  JOURNAL     = {Unpublished},
  MONTH       = Dec,
  PDF         = {https://hal.science/hal-03913837/file/ChatGPT.pdf}, HAL_ID      = {hal-03913837},
  HAL_VERSION = {v1},
}

@article{Zvyagin:2022,
  TITLE     = {GenSLMs: Genome-scale language models reveal SARS-CoV-2 evolutionary dynamics},
  AUTHOR    = {Zvyagin, Maxim and Brace, Alexander and Hippe, Kyle and Deng, Yuntian and Zhang, Bin and Bohorquez, Cindy Orozco and Clyde, Austin and Kale, Bharat and Perez-Rivera, Danilo and Ma, Heng and others},
  JOURNAL   = {bioRxiv},
  PAGES     = {2022--10},
  YEAR      = {2022},
  PUBLISHER = {Cold Spring Harbor Laboratory}
}

@article{Chatterjee:2023,
  TITLE     = {Can artificial intelligence-strengthened ChatGPT or other large language models transform nucleic acid research?},
  AUTHOR    = {Chatterjee, Srijan and Bhattacharya, Manojit and Lee, Sang-Soo and Chakraborty, Chiranjib},
  JOURNAL   = {Molecular Therapy-Nucleic Acids},
  VOLUME    = {33},
  PAGES     = {205--207},
  YEAR      = {2023},
  PUBLISHER = {Elsevier}
}

@ARTICLE{Lund:2023,
  TITLE     = {A Chat with ChatGPT: How will AI and GPT impact scholarly publishing? Citations, Rights, Re-Use},
  AUTHOR    = {Brady Lund},
  URL       = {https://digital.library.unt.edu/ark:/67531/metadc2041725/},
  YEAR      = {2023},
  JOURNAL   = {UNT College of Information},
  PUBLISHER = {University of North Texas Library},
  ABSTRACT  = {The paper has two parts. The first part is an overview of GPT technology and the ChatGPT
               interface. The second part is a transcript of an interview of sorts. This interview was unique in
               that it was not conducted with a living being, but rather an AI interface. All of the questions that
               you read come from a human user, but all of the answers (labeled “A:”) were written entirely by
               the platform ChatGPT, created by the OpenAI program. It should be noted that ChatGPT is not
               perfect and there are many issues that will be identified and improved upon in the future, but this
               paper gives a taste of the platform and how it may impact our scholarly publishing
               infrastructure.This paper will begin with an introduction to ChatGPT and then proceed into the
               transcript of a conversation with the platform about it and related AI technologies’ impact on the
               future of scholarly publishing, before concluding with some discussion on the further
               implications.}
}

@inproceedings{Tan:2017,
  AUTHOR       = {Tan, Haocheng},
  ABSTRACTNOTE = {The expert system is a computer system that emulates                  the decision-making ability of a human expert, which
                  aims to solve complex problems by reasoning knowledge. It is an important branch of artificial intelligence. In this paper, firstly, we briefly introduce the development and basic structure of the expert system. Then, from the perspective of the enabling technology, we classify the current expert systems and elaborate four expert systems: The Rule-Based Expert System, the Framework-Based Expert System, the Fuzzy Logic-Based Expert System and the Expert System Based on Neural Network.},
  TITLE        = {A brief history and technical review of the expert 
                  system research},
  BOOKTITLE    = {IOP Conference Series: Materials Science and 
                  Engineering},
  YEAR         = {2017},
  DOI          = {10.1088/1757-899X/242/1/012111},
  VOLUME       = {242}  
}

@book{RussellNorvig:2016,
  title     = {Artificial IntelligenceA Modern Approach},
  author    = {Russell, Stuart J. and Norvig, Peter},
  year      = {2016},
  edition   = {3},
  publisher = {Pearson Education Ltd.},
  address   = {London}
}

@misc{OpenAI:2023_gpt4,
      title={GPT-4 Technical Report}, 
      author={OpenAI},
      year={2023},
      eprint={2303.08774},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@ARTICLE{Deng:2011,
  title     = {A comprehensive overview of computational protein disorder prediction methods},
  author    = {Deng, Xin and Eickholt, Jesse and Cheng, Jianlin},
  year      = {2011},
  month     = {August},
  pages     = {114--121},
  volume    = {8},
  number    = {1},
  journal   = {Molecular Biosystems},
  publisher = {PubMed},
  url       = {https://pubmed.ncbi.nlm.nih.gov/21874190},
  doi       = {10.1039/c1mb05207a},
  abstract  = {Over the past decade there has been a growing acknowledgement that a large proportion of proteins within most proteomes contain disordered regions. Disordered regions are segments of the protein chain which do not adopt a stable structure. Recognition of disordered regions in a protein is of great importance for protein structure prediction, protein structure determination and function annotation as these regions have a close relationship with protein expression and functionality. As a result, a great many protein disorder prediction methods have been developed so far. Here, we present an overview of current protein disorder prediction methods including an analysis of their advantages and shortcomings. In order to help users to select alternative tools under different circumstances, we also evaluate 23 disorder predictors on the benchmark data of the most recent round of the Critical Assessment of protein Structure Prediction (CASP) and assess their accuracy using several complementary measures.}
}

@ARTICLE{Liang:2022:helm,
  TITLE   = {Holistic evaluation of language models},
  AUTHOR  = {Percy Liang and Rishi Bommasani and Tony Lee    
            and Dimitris Tsipras and Dilara Soylu and Michihiro Yasunaga and Yian Zhang and Deepak Narayanan and Yuhuai Wu and Ananya Kumar and Benjamin Newman and Binhang Yuan and Bobby Yan and Ce Zhang and Christian Cosgrove and Christopher D. Manning and Christopher Ré and Diana Acosta-Navas and Drew A. Hudson and Eric Zelikman and Esin Durmus and Faisal Ladhak and Frieda Rong and Hongyu Ren and Huaxiu Yao and Jue Wang and Keshav Santhanam and Laurel Orr and Lucia Zheng and Mert Yuksekgonul and Mirac Suzgun and Nathan Kim and Neel Guha and Niladri Chatterji and Omar Khattab and Peter Henderson and Qian Huang and Ryan Chi and Sang Michael Xie and Shibani Santurkar and Surya Ganguli and Tatsunori Hashimoto and Thomas Icard and Tianyi Zhang and Vishrav Chaudhary and William Wang and Xuechen Li and Yifan Mai and Yuhui Zhang and Yuta Koreeda},
  YEAR    = {2022},
  JOURNAL = {arXiv preprint arXiv:2211.09110},
  EPRINT  = {2211.09110},
}


@inproceedings{Blattgerste:2022,
  TITLE     = {A web-based analysis toolkit for the system usability scale},
  AUTHOR    = {Blattgerste, Jonas and Behrends, Jan and Pfeiffer, Thies},
  BOOKTITLE = {Proceedings of the 15th International Conference on PErvasive Technologies Related to Assistive Environments},
  PAGES     = {237--246},
  YEAR      = {2022}
}


@ARTICLE{Daull:2023:complex,
  TITLE   = {Complex QA and language models hybrid architectures, Survey},
  AUTHOR  = {Daull, Xavier and Bellot, Patrice and Bruno, Emmanuel and Martin, Vincent and Murisasco, Elisabeth},
  JOURNAL = {arXiv preprint arXiv:2302.09051},
  YEAR    = {2023}
}


@article{Gawehn:2016_deep,
  title     = {Deep learning in drug discovery},
  author    = {Gawehn, Erik and Hiss, Jan A and Schneider, Gisbert},
  journal   = {Molecular informatics},
  volume    = {35},
  number    = {1},
  pages     = {3--14},
  year      = {2016},
  publisher = {Wiley Online Library}
}

@article{Angermueller:2016,
  title   = {Deep learning for computational biology},
  author  = {Angermueller, Christof and 
             P{\"a}rnamaa, Tanel and 
             Parts, Leopold and 
             Stegle, Oliver},
  journal = {Molecular systems biology},
  volume  = {12},
  number  = {7},
  pages   = {878},
  year    = {2016}
}

@article{Min:2017,
  title     = {Deep learning in bioinformatics},
  author    = {Min, Seonwoo and Lee, Byunghan and Yoon, Sungroh},
  journal   = {Briefings in bioinformatics},
  volume    = {18},
  number    = {5},
  pages     = {851--869},
  year      = {2017},
  publisher = {Oxford University Press}
}

@article{Miotto:2018:deep,
  title     = {Deep learning for healthcare: review, opportunities and challenges},
  author    = {Miotto, Riccardo and Wang, Fei and Wang, Shuang and Jiang, Xiaoqian and Dudley, Joel T},
  journal   = {Briefings in bioinformatics},
  volume    = {19},
  number    = {6},
  pages     = {1236--1246},
  year      = {2018},
  publisher = {Oxford University Press}
}

@ARTICLE{Zhang:2019,
  title     = {Deep learning in omics: a survey and guideline},
  author    = {Zhang, Zhiquang and Zhao, Yi and Liao, Xiangke and Shi, Wenqiang and Li, Kenli and Zou, Quan and Peng, Shaoliang},
  year      = {2019},
  month     = {February},
  pages     = {41--57},
  volume    = {18},
  number    = {1},
  journal   = {Briefing in Functional Genetics},
  publisher = {NLM},
  url       = {https://academic.oup.com/bfg/article/18/1/41/5107348},
  doi       = {10.1093/bfgp/ely030},
  abstract  = {Omics, such as genomics, transcriptome and proteomics, has been affected by the era of big data. A huge amount of high dimensional and complex structured data has made it no longer applicable for conventional machine learning algorithms. Fortunately, deep learning technology can contribute toward resolving these challenges. There is evidence that deep learning can handle omics data well and resolve omics problems. This survey aims to provide an entry-level guideline for researchers, to understand and use deep learning in order to solve omics problems. We first introduce several deep learning models and then discuss several research areas which have combined omics and deep learning in recent years. In addition, we summarize the general steps involved in using deep learning which have not yet been systematically discussed in the existent literature on this topic. Finally, we compare the features and performance of current mainstream open source deep learning frameworks and present the opportunities and challenges involved in deep learning. This survey will be a good starting point and guideline for omics researchers to understand deep learning.}
}

@ARTICLE{Tran:2018,
  author   = {Tran, Ngoc Hieu and Zhang, Xianglilan and Li, Ming},
  title    = {Deep Omics},
  journal  = {PROTEOMICS},
  year     = {2018},
  volume   = {18},
  number   = {2},
  pages    = {1700319},
  keywords = {big data, bioinformatics, deep learning, genomics, neural networks, proteomics},
  doi      = {https://doi.org/10.1002/pmic.201700319},
  url      = {https://analyticalsciencejournals.onlinelibrary.wiley.com/doi/abs/10.1002/pmic.201700319},
  eprint   = {https://analyticalsciencejournals.onlinelibrary.wiley.com/doi/pdf/10.1002/pmic.201700319},
  abstract = {Abstract Deep learning has revolutionized research in image processing, speech recognition, natural language processing, game playing, and will soon revolutionize research in proteomics and genomics. Through three examples in genomics, protein structure prediction, and proteomics, we demonstrate that deep learning is changing bioinformatics research, shifting from algorithm-centric to data-centric approaches.},
}

@article{Toh:2019,
title    = {Looking beyond the hype: Applied AI and machine learning in translational medicine},
author   = {Tzen S. Toh and Frank Dondelinger and Dennis Wang},
journal  = {EBioMedicine},
volume   = {47},
pages    = {607-615},
year     = {2019},
issn     = {2352-3964},
doi      = {https://doi.org/10.1016/j.ebiom.2019.08.027},
url      = {https://www.sciencedirect.com/science/article/pii/S2352396419305493},
keywords = {Machine learning, Drug discovery, Imaging, Genomic medicine, 
            Artificial intelligence, Translational medicine},
abstract = {Big data problems are becoming more prevalent for laboratory scientists who look to make clinical impact. A large part of this is due to increased computing power, in parallel with new technologies for high quality data generation. Both new and old techniques of artificial intelligence (AI) and machine learning (ML) can now help increase the success of translational studies in three areas: drug discovery, imaging, and genomic medicine. However, ML technologies do not come without their limitations and shortcomings. Current technical limitations and other limitations including governance, reproducibility, and interpretation will be discussed in this article. Overcoming these limitations will enable ML methods to be more powerful for discovery and reduce ambiguity within translational medicine, allowing data-informed decision-making to deliver the next generation of diagnostics and therapeutics to patients quicker, at lowered costs, and at scale.}
}

@article{Bouwmeester:2020,
  title     = {The age of data-driven proteomics: how machine learning enables novel workflows},
  author    = {Bouwmeester, Robbin and Gabriels, Ralf and Van Den Bossche, Tim and Martens, Lennart and Degroeve, Sven},
  journal   = {Proteomics},
  volume    = {20},
  number    = {21-22},
  pages     = {1900351},
  year      = {2020},
  publisher = {Wiley Online Library}
}

@article{Wen:2020:deep,
  title     = {Deep learning in proteomics},
  author    = {Wen, Bo and Zeng, Wen-Feng and Liao, Yuxing and Shi, Zhiao and Savage, Sara R and Jiang, Wen and Zhang, Bing},
  journal   = {Proteomics},
  volume    = {20},
  number    = {21-22},
  pages     = {1900335},
  year      = {2020},
  publisher = {Wiley Online Library}
}

@article{Caudai:2021,
  title     = {AI applications in functional genomics},
  author    = {Caudai, Claudia and Galizia, Antonella and Geraci, Filippo and Le Pera, Loredana and Morea, Veronica and Salerno, Emanuele and Via, Allegra and Colombo, Teresa},
  journal   = {Computational and Structural Biotechnology Journal},
  volume    = {19},
  pages     = {5762--5790},
  year      = {2021},
  publisher = {Elsevier}
}

@article{Talukder:2021,
    author   = {Talukder, Amlan and Barham, Clayton and Li, Xiaoman and Hu, Haiyan},
    title    = "{Interpretation of deep learning in genomics and epigenomics}",
    journal  = {Briefings in Bioinformatics},
    volume   = {22},
    number   = {3},
    year     = {2021},
    month    = {08},
    issn     = {1477-4054},
    doi      = {10.1093/bib/bbaa177},
    url      = {https://doi.org/10.1093/bib/bbaa177},
    note     = {bbaa177},
    eprint   = {https://academic.oup.com/bib/article-pdf/22/3/bbaa177/37966280/bbaa177.pdf},
    abstract = "{Machine learning methods have been widely applied to big data analysis in genomics and epigenomics research. Although accuracy and efficiency are common goals in many modeling tasks, model interpretability is especially important to these studies towards understanding the underlying molecular and cellular mechanisms. Deep neural networks (DNNs) have recently gained popularity in various types of genomic and epigenomic studies due to their capabilities in utilizing large-scale high-throughput bioinformatics data and achieving high accuracy in predictions and classifications. However, DNNs are often challenged by their potential to explain the predictions due to their black-box nature. In this review, we present current development in the model interpretation of DNNs, focusing on their applications in genomics and epigenomics. We first describe state-of-the-art DNN interpretation methods in representative machine learning fields. We then summarize the DNN interpretation methods in recent studies on genomics and epigenomics, focusing on current data- and computing-intensive topics such as sequence motif identification, genetic variations, gene expression, chromatin interactions and non-coding RNAs. We also present the biological discoveries that resulted from these interpretation methods. We finally discuss the advantages and limitations of current interpretation approaches in the context of genomic and epigenomic studies. Contact:xiaoman at mail.ucf.edu, haihu at cs.ucf.edu}",
}

@misc{Hassabis:2022,
  title            = {AlphaFold reveals the structure 
                      of the protein universe},
  author           = {Hassabis, Demis},
  publisher        = {DeepMind},
  publication_date = {07-28-2022},
  year             = {2022},
  month            = {July},
  journal          = {DeepMind Blog},
  link             = {https://www.deepmind.com/blog/alphafold-reveals-the-structure-of-the-protein-universe}
}

@article{Weng:2022,
  TITLE     = {Techniques for training large neural networks},
  AUTHOR    = {Weng, Lilian and Brockman, Greg},
  JOURNAL   = {OpenAI Research},
  PUBLISHER = {openai.com},
  URL       = {https://openai.com/research/techniques-for-training-large-neural-networks}
  YEAR      = {2022}
}

@article{Bavarian:2022,
  TITLE   = {Efficient training of language models to fill in the middle},
  AUTHOR  = {Bavarian, Mohammad and Jun, Heewoo and Tezak, Nikolas and Schulman, John and McLeavey, Christine and Tworek, Jerry and Chen, Mark},
  JOURNAL = {arXiv preprint arXiv:2207.14255},
  YEAR    = {2022}
}

@ARTICLE{Liao:2005,
  TITLE    = {Expert system methodologies and applications—
              a decade review from 1995 to 2004},
  JOURNAL  = {Expert Systems with Applications},
  VOLUME   = {28},
  NUMBER   = {1},
  PAGES    = {93-103},
  YEAR     = {2005},
  ISSN     = {0957-4174},
  DOI      = {https://doi.org/10.1016/j.eswa.2004.08.003},
  URL      = {https://www.sciencedirect.com/science/article/pii/S0957417404000934},
  AUTHOR   = { {Shu-Hsien Liao}},
  KEYWORDS = {Expert systems, Expert system methodologies, Expert 
              system applications, Literature survey},
  ABSTRACT = {This paper surveys expert systems (ES) development using 
              a literature review and classification of articles from 1995 to 2004 with a keyword index and article abstract in order to explore how ES methodologies and applications have developed during this period. Based on the scope of 166 articles from 78 academic journals (retrieved from five online database) of ES applications, this paper surveys and classifies ES methodologies using the following eleven categories: rule-based systems, knowledge-based systems, neural networks, fuzzy ESs, object-oriented methodology, case-based reasoning, system architecture, intelligent agent systems, database methodology, modeling, and ontology together with their applications for different research and problem domains. Discussion is presented, indicating the followings future development directions for ES methodologies and applications: (1) ES methodologies are tending to develop towards expertise orientation and ES applications development is a problem-oriented domain. (2) It is suggested that different social science methodologies, such as psychology, cognitive science, and human behavior could implement ES as another kind of methodology. (3) The ability to continually change and obtain new understanding is the driving power of ES methodologies, and should be the ES application of future works.}
}

@ARTICLE{Ferrucci:2010_watson,
  AUTHOR       = {Ferrucci, David and Brown, Eric and Chu-Carroll, Jennifer and 
                  Fan, James and Gondek, David and Kalyanpur, Aditya A. and 
                  Lally, Adam and Murdock, J. William and Nyberg, Eric and 
                  Prager, John and Schlaefer, Nico and Welty, Chris},
  ABSTRACTNOTE = {IBM Research undertook a challenge to build a computer system
                  that could compete at the human champion level in real time 
                  on the American TV Quiz show, Jeopardy! The extent of the 
                  challenge includes fielding a real-time automatic contestant 
                  on the show, not merely a laboratory exercise. The Jeopardy! 
                  Challenge helped us address requirements that led to the 
                  design of the DeepQA architecture and the implementation of 
                  Watson. After 3 years of intense research and development by 
                  a core team of about 20 researches, Watson is performing at 
                  human expert-levels in terms of precision, confidence and 
                  speed at the Jeopardy! Quiz show. Our results strongly 
                  suggest that DeepQA is an effective and extensible 
                  architecture that may be used as a foundation for combining, 
                  deploying, evaluating and advancing a wide range of 
                  algorithmic techniques to rapidly advance the field of QA.}, 
  TITLE        = {Building Watson: An Overview of the DeepQA Project}, 
  URL          = {https://ojs.aaai.org/aimagazine/index.php/aimagazine/article/view/2303},
  DOI          = {10.1609/aimag.v31i3.2303},
  VOLUME       = {31}, 
  NUMBER       = {3},
  JOURNAL      = {AI Magazine}, 
  YEAR         = {2010}, 
  MONTH        = {Jul.}, 
  PAGES        = {59-79} 
}

@article{Lund:2023_chatting,
  TITLE     = {Chatting about ChatGPT: how may AI and GPT impact academia and libraries?},
  AUTHOR    = {Lund, Brady D and Wang, Ting},
  JOURNAL   = {Library Hi Tech News},
  VOLUME    = {40},
  NUMBER    = {3},
  PAGES     = {26--29},
  YEAR      = {2023},
  PUBLISHER = {Emerald Publishing Limited}
}

@ARTICLE{Zhang:2023,
  AUTHOR  = {Zhang, Bo},
  YEAR    = {2023},
  MONTH   = {01},
  PAGES   = {},
  JOURNAL = {Unpublished},
  TITLE   = {Preparing Educators and Students for ChatGPT and AI Technology in Higher Education:Benefits, Limitations, Strategies, and Implications of ChatGPT \& AI Technologies.},
  DOI     = {10.13140/RG.2.2.32105.98404}
}

@article{Williams:2023,
  TITLE   = {Algorithmic Ghost in the Research Shell: Large Language Models and 
             Academic Knowledge Creation in Management Research},
  AUTHOR  = {Williams, Nigel and Ivanov, Stanislav and Buhalis, Dimitrios},
  JOURNAL = {arXiv preprint arXiv:2303.07304},
  YEAR    = {2023},
}

@inproceedings{Zhang:2022,
  TITLE     = {Probing GPT-3’s linguistic knowledge on semantic tasks},
  AUTHOR    = {Zhang, Lining and Wang, Mengchen and Chen, Liben and Zhang, Wenxin},
  BOOKTITLE = {Proceedings of the Fifth BlackboxNLP Workshop on Analyzing and 
               Interpreting Neural Networks for NLP},
  PAGES     = {297--304},
  YEAR      = {2022}
}

@article{Bommasani:2021_opportunities,
  TITLE   = {On the opportunities and risks of foundation models},
  AUTHOR  = {Bommasani, Rishi and Hudson, Drew A and Adeli, Ehsan and Altman, Russ 
            and Arora, Simran and von Arx, Sydney and Bernstein, Michael S 
            and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and others},
  JOURNAL = {arXiv preprint arXiv:2108.07258},
  URL     = {https://arxiv.org/pdf/2108.07258.pdf},
  YEAR    = {2021}
}

@article{Vallet:2022_guix,
  title     = {Toward practical transparent verifiable and long-term reproducible research using Guix},
  author    = {Vallet, Nicolas and Michonneau, David and Tournier, Simon},
  journal   = {Scientific Data},
  volume    = {9},
  number    = {1},
  pages     = {597},
  year      = {2022},
  publisher = {Nature Publishing Group UK London}
}

@MISC{Glaze:2023,
  TITLE     = {How we built better GenAI with programmatic data development},
  AUTHOR    = {Glaze, Chris},
  YEAR      = {2023},
  MONTH     = {07},
  PUBLISHER = {Snorkel.ai},
  URL       = {https://snorkel.ai/how-we-built-better-genai-with-programmatic-data-development}
}

@article{Dao:2023,
  title={Performance comparison of large language models on vnhsge english dataset: Openai chatgpt, microsoft bing chat, and google bard},
  author={Dao, Xuan-Quy},
  journal={arXiv preprint arXiv:2307.02288},
  year={2023}
}

@article{Dao:2023_chatgpt,
  title={Chatgpt is good but bing chat is better for vietnamese students},
  author={Dao, Xuan-Quy and Le, Ngoc-Bich},
  journal={arXiv preprint arXiv:2307.08272},
  year={2023}
}

@inproceedings{Liu:2022_oag,
  TITLE     = {Oag-bert: Towards a unified backbone language model for academic knowledge services},
  AUTHOR    = {Liu, Xiao and Yin, Da and Zheng, Jingnan and Zhang, Xingjian and Zhang, Peng and Yang, 
               Hongxia and Dong, Yuxiao and Tang, Jie},
  BOOKTITLE = {Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
  PAGES     = {3418--3428},
  YEAR      = {2022}
}

@ARTICLE{Arora:2022_ask,
      TITLE   = {Ask Me Anything: A simple strategy for prompting language models}, 
      AUTHOR  = {Simran Arora and Avanika Narayan and Mayee F. Chen and Laurel Orr 
                and Neel Guha and Kush Bhatia and Ines Chami and Frederic Sala and Christopher Ré},
      YEAR    = {2022},
      EPRINT  = {2210.02441},
      JOURNAL = {arXiv}
}

@article{Ferrucci:2010, 
  AUTHOR   = {Ferrucci, David and Brown, Eric and Chu-Carroll, Jennifer and 
             Fan, James and Gondek, David and Kalyanpur, Aditya A. and 
             Lally, Adam and Murdock, J. William and Nyberg, Eric and 
             Prager, John and Schlaefer, Nico and Welty, Chris}, 
  TITLE    = {Building Watson: An Overview of the DeepQA Project}, 
  VOLUME   = {31}, 
  URL      = {https://ojs.aaai.org/aimagazine/index.php/aimagazine/article/view/2303}, 
  DOI      = {10.1609/aimag.v31i3.2303}, 
  NUMBER   = {3}, 
  JOURNAL  = {AI Magazine}, 
  YEAR     = {2010}, 
  MONTH    = {Jul.}, 
  PAGES    = {59-79}, 
  ABSTRACT = {IBM Research undertook a challenge to build a computer system that could compete at the 
              human champion level in real time on the American TV Quiz show, Jeopardy! The extent of 
              the challenge includes fielding a real-time automatic contestant on the show, not merely 
              a laboratory exercise. The Jeopardy! Challenge helped us address requirements that led to 
              the design of the DeepQA architecture and the implementation of Watson. After 3 years of 
              intense research and development by a core team of about 20 researches, Watson is 
              performing at human expert-levels in terms of precision, confidence and speed at the 
              Jeopardy! Quiz show. Our results strongly suggest that DeepQA is an effective and 
              extensible architecture that may be used as a foundation for combining, deploying, 
              evaluating and advancing a wide range of algorithmic techniques to rapidly advance the 
              field of QA.}
}

@misc{Foucart:2023,
  AUTHOR       = {Foucart, Adrien},
  TITLE        = {{Can ChatGPT write an academic paper? Review of "A 
                   Day in the Life of ChatGPT"}},
  MONTH        = jan,
  YEAR         = 2023,
  NOTE         = {While the author is affiliated with the LISA 
                   laboratory ofthe Université Libre de Bruxelles,
                   this work was done independently from the research
                   group and does not aim to follow usual academic
                   standards. It was originally written as a blog
                   post on the author's personal research blog.},
  PUBLISHER    = {Zenodo},
  DOI          = {10.5281/zenodo.7514987},
  URL          = {https://doi.org/10.5281/zenodo.7514987}
}

@ARTICLE{Stone:2011,
  TITLE     = {Non-conscious bias in medical decision making: what can be done to reduce it?},
  AUTHOR    = {Jeff Stone and Gordon B Moskowitz},
  URL       = {https://asmepublications.onlinelibrary.wiley.com/doi/full/10.1111/j.1365-2923.2011.04026.x},
  YEAR      = {2011},
  MONTH     = {7},
  JOURNAL   = {Medical Education},
  VOLUME    = {45},
  DOI       = {10.1111/j.1365-2923.2011.04026.x},
  PUBLISHER = {Association for the Study of Medical Education (ASME)},
  PAGES     = {768--776},
  EPRINT    = {https://asmepublications.onlinelibrary.wiley.com/doi/pdf/10.1111/j.1365-2923.2011.04026.x},
  ABSTRACT  = {Medical Education 2011: 45: 768–776 Context  
             Non-conscious stereotyping and prejudice contribute to racial and ethnic disparities in health care. Contemporary training in cultural competence is insufficient to reduce these problems because even educated, culturally sensitive, egalitarian individuals can activate and use their biases without being aware they are doing so. However, these problems can be reduced by workshops and learning modules that focus on the psychology of non-conscious bias. The Psychology of NON-Conscious Bias  Research in social psychology shows that over time stereotypes and prejudices become invisible to those who rely on them. Automatic categorisation of an individual as a member of a social group can unconsciously trigger the thoughts (stereotypes) and feelings (prejudices) associated with that group, even if these reactions are explicitly denied and rejected. This implies that, when activated, implicit negative attitudes and stereotypes shape how medical professionals evaluate and interact with minority group patients. This creates differential diagnosis and treatment, makes minority group patients uncomfortable and discourages them from seeking or complying with treatment. Pitfalls in Cultural Competence Training  Cultural competence training involves teaching students to use race and ethnicity to diagnose and treat minority group patients, but to avoid stereotyping them by over-generalising cultural knowledge to individuals. However, the Culturally and Linguistically Appropriate Services (CLAS) standards do not specify how these goals should be accomplished and psychological research shows that common approaches like stereotype suppression are ineffective for reducing non-conscious bias. To effectively address bias in health care, training in cultural competence should incorporate research on the psychology of non-conscious stereotyping and prejudice. Training in Implicit Bias Enhances Cultural Competence  Workshops or other learning modules that help medical professionals learn about non-conscious processes can provide them with skills that reduce bias when they interact with minority group patients. Examples of such skills in action include automatically activating egalitarian goals, looking for common identities and counter-stereotypical information, and taking the perspective of the minority group patient.}
}

@ARTICLE{Hadi:2023:survey,
  TITLE   = {A survey on large language models: Applications, challenges, limitations, and practical usage},
  AUHOR   = {Hadi, Muhammad Usman and Qureshi, R and Shah, A 
             and Irfan, M and Zafar, A and Shaikh, MB and Akhtar, N and Wu, J and Mirjalili, S},
  JOURNAL = {TechRxiv},
  YEAR    = {2023}
}

@MISC{Sun:2023,
      TITLE   = {A Short Survey of Viewing Large Language Models in Legal Aspect}, 
      AUTHOR  = {Zhongxiang Sun},
      JOURNAL = {arXiv},
      EPRINT  = {2303.09136},
      URL     = {https://arxiv.org/pdf/2303.09136.pdf},
      YEAR    = {2023}
}


@misc{OpenAI:2023:gpt4,
  title  = {GPT-4 Technical Report}, 
  author = {OpenAI},
  year   = {2023},
  eprint = {2303.08774}
}

@misc{GoogleBard:2023,
  title  = {A message from our CEO: An important next step on our AI journey.}, 
  author = {Sundar Pichai},
  JOURNAL = {Google Blog},
  year    = {2023}
}

@misc{Dolly:2023,
  author = {Mike Conover and Matt Hayes and Ankit Mathur and Jianwei Xie and Jun Wan and Sam Shah and Ali Ghodsi and Patrick Wendell and Matei Zharaia and Reynold Xin},
  title  = {Free Dolly: Introducing th World's First Truly Open Instruction-Tuned LLM}, 
  JOURNAL = {Databrick Blog},
  year    = {2023},
  URL     = {https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm}
}

@misc{BingChat:2023,
  author  = {Yusuf Mehdi},
  title   = {Reinventing search with a new AI-powered Microsoft Bing and Edge, your copilot for the web}, 
  JOURNAL = {Official Microsoft Blog},
  year    = {2023},
  URL     = {https://blogs.microsoft.com/blog/2023/07/18/furthering-our-ai-ambitions-announcing-bing-chat-enterprise-and-microsoft-365-copilot-pricing/}
}

@article{Llama:2023,
  title   = {Llama: Open and efficient foundation language models},
  author  = {Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal = {arXiv preprint arXiv:2302.13971},
  year    = {2023}
}


@article{Llama2:2023,
  title  = {Llama 2: Open foundation and fine-tuned chat models},
  author = {Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal= {arXiv preprint arXiv:2307.09288},
  year   = {2023},
  URL    = {https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/}
}

\iffalse
@ARTICLE{YEARFIRSTAUTHOR,
  TITLE     = {},
  AUTHOR    = {},
  URL       = {},
  YEAR      = {},
  MONTH     = {},
  JOURNAL   = {},
  VOLUME    = {},
  DOI       = {},
  PUBLISHER = {},
  ABSTRACT  = {}
}
\fi